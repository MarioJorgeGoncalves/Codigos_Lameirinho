{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEITURA DOS ARQUIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_dados_pickle(caminho_arquivo_pkl):\n",
    "    \"\"\"Carrega os dados de um arquivo .pkl em um DataFrame.\"\"\"\n",
    "    # Indexar o DataFrame pela coluna 'Data'\n",
    "    return pd.read_pickle(caminho_arquivo_pkl)\n",
    "\n",
    "### Nova Chamada 1: Carregar dados de todos os arquivos .pkl no diretório ###\n",
    "caminho_arquivos_pkl = glob.glob(r'H:\\Path_Python\\Dados_Python_2024\\Lameirinho\\Ficheiros_PKL_Saida\\Arquivos_com_NaNs_preenchidos\\*.pkl')\n",
    "\n",
    "# Definir a pasta de saída desejada\n",
    "pasta_saida_desejada = r'H:\\Path_Python\\Dados_Python_2024\\Lameirinho\\Ficheiros_PKL_Saida\\Arquivos_com_series_temporais_regularizadas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def ler_dados_pickle(caminho_arquivo_pkl):\n",
    "# #     return pd.read_pickle(caminho_arquivo_pkl)\n",
    "# # # Caminho completo para o arquivo .pkl\n",
    "# caminho_arquivos_pkl = r'C:\\Users\\MarioGoncalves\\Dados_Python_2024\\Lameirinho\\Ficheiros_PKL_Saida\\Arquivos_com_NaNs_preenchidos\\dados_lameirinho_26_02_2024_sem_missing_values.pkl'\n",
    "\n",
    "# # Ler o arquivo .pkl em um DataFrame\n",
    "# df = pd.read_pickle(caminho_arquivos_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNÇÕES\n",
    "\n",
    "## FUNÇÃO 1: Construção do dataframe com uma coluna datetime para melhorar a regularização das séries temporais dos dados\n",
    "def preprocess_dataframe(df):\n",
    "    \"\"\"Realiza o pré-processamento no DataFrame.\"\"\"\n",
    "    # Combinar as colunas 'Data' e 'Hora' em uma coluna Datetime\n",
    "    df['Datetime'] = pd.to_datetime(df['Data'] + df['Hora'], format='%d/%m/%Y%H:%M:%S')\n",
    "    # Remover as colunas 'Data' e 'Hora'\n",
    "    df.drop(columns=['Data', 'Hora'], inplace=True)\n",
    "    # Definir a nova coluna 'Datetime' como índice\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    # Ordenar o DataFrame pelo índice (coluna 'Datetime')\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "# ### FUNÇÃO 2: Aplicar a regularização temporal de 1S\n",
    "# def regularize_dataframe(df):\n",
    "#     \"\"\"Regulariza o DataFrame por segundo e interpola os valores ausentes.\"\"\"\n",
    "#     # Obter os períodos ausentes formatados\n",
    "#     missing_periods = get_formated_missing_periods(df, tresh_timedelta_str='1S')\n",
    "#     # Regularizar o DataFrame por segundo e interpolar os valores ausentes\n",
    "#     df_regularized = regularize_series(df, freq='1S', exclude_ranges=missing_periods)\n",
    "#     return df_regularized\n",
    "\n",
    "### FUNÇÃO 2: Aplicar a regularização temporal de 1S\n",
    "# def regularize_dataframe(df):\n",
    "#     \"\"\"Regulariza o DataFrame por segundo e interpola os valores ausentes.\"\"\"\n",
    "#     # Obter os períodos ausentes formatados\n",
    "#     #missing_periods = get_formated_missing_periods(df, tresh_timedelta_str='1S')\n",
    "#     # Regularizar o DataFrame por segundo e interpolar os valores ausentes\n",
    "#     df_regularized = regularize_series(df, freq='1S')\n",
    "#     return df_regularized\n",
    "\n",
    "### FUNÇÃO 3: Formatar os Missing_values (nao foi aplicada porque os intrvalos de missing values são pequenos entre todos os dados elétricos)\n",
    "# def get_formated_missing_periods(in_df, tresh_timedelta_str):\n",
    "#     \"\"\"Encontra os períodos ausentes no DataFrame.\"\"\"\n",
    "#     df = in_df.copy()\n",
    "#     # Delta da data anterior\n",
    "#     df['dif'] = df.index.to_series().diff()\n",
    "#     # Apenas mantém os períodos maiores que tresh_timedelta_str\n",
    "#     missing_periods_idxs = df[df['dif'] > pd.Timedelta(tresh_timedelta_str)].index\n",
    "#     # Obtém as posições inteiras\n",
    "#     int_missing_periods_idxs = np.where(df.index.isin(missing_periods_idxs))[0]\n",
    "    \n",
    "#     missing_periods = []\n",
    "#     # Loop para obter as datas de início e fim para cada período ausente selecionado\n",
    "#     for int_idx in int_missing_periods_idxs:\n",
    "#         missing_periods.append([str(df.index[int_idx-1]), str(df.index[int_idx])])\n",
    "    \n",
    "#     return missing_periods\n",
    "\n",
    "### FUNÇÃO 4: Regularizar as séries temporais\n",
    "def regularize_series(df, freq, exclude_ranges=None, start_date=None, end_date=None):\n",
    "    \"\"\"Regulariza o DataFrame para uma frequência específica.\"\"\"\n",
    "    if start_date is None:\n",
    "        start_date = df.index.min()\n",
    "    if end_date is None:\n",
    "        end_date = df.index.max()\n",
    "\n",
    "    # Cria uma série temporal regular sem valores\n",
    "    reg_freq = pd.DataFrame(index=pd.date_range(start_date, end_date, freq=freq))\n",
    "    # Combina ambos para obter um DataFrame com todos os Datetimes\n",
    "    df_add_reg_freq = pd.merge(df, reg_freq, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "    # Remove linhas dos períodos a não serem interpolados\n",
    "    if exclude_ranges is not None:\n",
    "        try:\n",
    "            for exclude_range in exclude_ranges:\n",
    "                df_add_reg_freq = df_add_reg_freq.loc[\n",
    "                    (df_add_reg_freq.index < exclude_range[0]) |\n",
    "                    (df_add_reg_freq.index > exclude_range[1])]\n",
    "        except:\n",
    "            raise ValueError('exclude_dates must be in format [[start, end], ...]')\n",
    "    \n",
    "    # Interpola para obter valores em cada intervalo regular\n",
    "    df_add_reg_freq.interpolate(method='time', inplace=True)\n",
    "    # Adiciona de volta o período removido, mas com intervalos regulares com NaNs\n",
    "    df_add_reg_freq = pd.merge(df_add_reg_freq, reg_freq, left_index=True, right_index=True, how='outer')\n",
    "    # Remove Datetimes fora do intervalo regular\n",
    "    df_add_reg_freq = df_add_reg_freq.loc[df_add_reg_freq.index.isin(reg_freq.index)]\n",
    "    df_add_reg_freq.index.set_names(df.index.name, inplace=True)\n",
    "    \n",
    "    return df_add_reg_freq\n",
    "\n",
    "# def add_date_time_columns(df):\n",
    "#     \"\"\"Adiciona colunas de Data e Hora ao DataFrame a partir do índice Datetime.\"\"\"\n",
    "#     # Extrair colunas de Data e Hora do índice Datetime\n",
    "#     df['Data'] = df.index.date\n",
    "#     df['Hora'] = df.index.time\n",
    "#     return df\n",
    "\n",
    "### FUNÇÃO 5: Salvar o DataFrame como um arquivo pickle e, opcionalmente, um arquivo CSV ###\n",
    "def salvar_arquivos(df, caminho_arquivo_pkl, pasta_saida, save_csv=True):\n",
    "    \"\"\"Salva o DataFrame como um arquivo pickle e, opcionalmente, um arquivo CSV.\"\"\"\n",
    "    caminho_arquivo_pkl_regularizado = os.path.join(pasta_saida, os.path.basename(caminho_arquivo_pkl).replace('.pkl', '_com_serie_regularizada_1S.pkl'))\n",
    "\n",
    "    # Salvar o arquivo pickle\n",
    "    df.to_pickle(caminho_arquivo_pkl_regularizado)\n",
    "\n",
    "    # Salvar o arquivo CSV, se a opção save_csv for True\n",
    "    if save_csv:\n",
    "        caminho_arquivo_csv = os.path.join(pasta_saida, os.path.basename(caminho_arquivo_pkl).replace('.pkl', '_com_serie_regularizada_1S.csv'))\n",
    "        df.to_csv(caminho_arquivo_csv, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHAMADA DAS FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada caminho de arquivo\n",
    "for caminho_arquivo_pkl in caminho_arquivos_pkl:\n",
    "    # Carregar o DataFrame a partir do arquivo .pkl\n",
    "    df = ler_dados_pickle(caminho_arquivo_pkl)\n",
    "\n",
    "    ### CHAMADA da Função 1: Corrigir o Data Hora para Datetime (uma coluna apenas)\n",
    "    df = preprocess_dataframe(df)\n",
    "\n",
    "    # ### CHAMADA da Função 2: Regularizar dataframe\n",
    "    # df = regularize_dataframe(df)\n",
    "\n",
    "    ### CHAMADA da Função 3: 'opcional'\n",
    "\n",
    "    ### CHAMADA da Função 4: para regularizar a série temporal em escalas de 1 segundo a partir da data de início\n",
    "    # Determinar a data de início e de fim com base no nome do arquivo\n",
    "\n",
    "\n",
    "\n",
    "    if 'dados_lameirinho_P 05_02_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-01-29 09:33:08'\n",
    "\n",
    "    elif 'dados_lameirinho_5_fev_14_fev_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-02-05 09:07:56'\n",
    "\n",
    "    elif 'dados_lameirinho_P_19_02_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-02-14 09:10:50'\n",
    "\n",
    "    elif 'dados_lameirinho_26_02_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-02-19 09:56:17'\n",
    "\n",
    "    elif 'dados_lameirinho_CP_26_02_04_03_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-02-26 09:09:26'\n",
    "\n",
    "    elif 'dados_lameirinho_CP_11_03_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-03-04 16:25:10'\n",
    "\n",
    "    elif 'dados_lameirinho_11_03_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-03-11 19:23:53'\n",
    "\n",
    "    elif 'dados_lameirinho_CP_25_03_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-03-18 16:10:07'\n",
    "\n",
    "    elif 'dados_lameirinho_P_25_3_08_04_2024_NEW_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-03-25 15:09:05'\n",
    "\n",
    "    elif 'dados_lameirinho_8_4_15_04_2024_NEW_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-04-08 09:39:41'\n",
    "\n",
    "    elif 'dados_lameirinho_15_04_22_04_2024_NEW_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-04-15 14:03:05'\n",
    "\n",
    "    elif 'dados_lameirinho_22_04_29_04_2024_NEW_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-04-22 14:51:11'\n",
    "\n",
    "    elif 'dados_lameirinho_CP_29_04_06_05_2024_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-04-22 09:06:06'\n",
    "\n",
    "    elif 'dados_lameirinho_06_05_13_05_2024_sem_excesso_original_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-05-06 17:30:24'\n",
    "\n",
    "    elif 'dados_lameirinho_E_CP_13_05_20_05_sem_missing_values' in caminho_arquivo_pkl:\n",
    "        start_date = '2024-05-13 10:22:16'\n",
    "\n",
    "       \n",
    "    # Adicionar a chamada da função `regularize_series` com a data específica\n",
    "    df = regularize_series(df, '1S', start_date=start_date)\n",
    "\n",
    "    # ### Adicionar colunas de Data e Hora ao DataFrame\n",
    "    # df = add_date_time_columns(df)\n",
    "\n",
    "    # ### CHAMADA da Função 5: salvar os arquivos na pasta de saída desejada\n",
    "    salvar_arquivos(df, caminho_arquivo_pkl, pasta_saida_desejada, save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
