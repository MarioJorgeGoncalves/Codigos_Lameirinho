{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEITURA DOS ARQUIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_dados_pickle(caminho_arquivo_pkl):\n",
    "    \"\"\"Carrega os dados de um arquivo .pkl em um DataFrame.\"\"\"\n",
    "    return pd.read_pickle(caminho_arquivo_pkl)\n",
    "\n",
    "### Nova Chamada 1: Carregar dados de todos os arquivos .pkl no diretório ###\n",
    "caminho_arquivos_pkl = glob.glob(r'H:\\Path_Python\\Dados_Python_2024\\Lameirinho\\Ficheiros_PKL_Entrada\\*.pkl')\n",
    "\n",
    "# Definir a pasta de saída desejada\n",
    "pasta_saida_desejada = r'H:\\Path_Python\\Dados_Python_2024\\Lameirinho\\Ficheiros_PKL_Saida\\Arquivos_com_NaNs_preenchidos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNÇÕES\n",
    "\n",
    "### FUNÇÃO 2: Deletar colunas específicas do DataFrame ###\n",
    "def deletar_colunas(df):\n",
    "    \"\"\"Deleta colunas específicas do DataFrame.\"\"\"\n",
    "    colunas = [x for x in range(df.shape[1])]  # list of columns' integer indices\n",
    "    colunas_para_deletar = [2, 3, 24, 26, 27, 28, 42, 43] # colunas a serem removidas\n",
    "    for coluna_para_deletar in colunas_para_deletar:\n",
    "        colunas.remove(coluna_para_deletar)\n",
    "    return df.iloc[:, colunas]\n",
    "\n",
    "### FUNÇÃO 3: Substituir valores comentados por NaN ###\n",
    "def substituir_valores_comentados_por_nan(df):\n",
    "    \"\"\"Substitui os valores que começam com '#' por NaN em todo o DataFrame.\"\"\"\n",
    "    return df.replace(to_replace=r'^#.*', value=np.nan, regex=True)\n",
    "\n",
    "### FUNÇÃO 4: Substituir virgulas por pontos\n",
    "def substituir_virgulas_por_pontos(df):\n",
    "    df = df.applymap(lambda x: str(x).replace(',', '.'))\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 5: Converter strings que representam NaN para NaN numérico ###\n",
    "def converter_str_nan_para_numerico(df):\n",
    "    \"\"\"Converte strings que representam NaN para NaN numérico.\"\"\"\n",
    "    return df.replace({'nan': np.nan, 'NaN': np.nan, 'NAN': np.nan})\n",
    "\n",
    "### FUNÇÃO 6: Preencher os NaN em cada coluna com a média dos valores anteriores e posteriores ###\n",
    "def preencher_nans_com_media(df, colunas_para_preencher):\n",
    "    \"\"\"Preenche os NaN em cada coluna com a média dos valores anteriores e posteriores.\"\"\"\n",
    "    for coluna in colunas_para_preencher:\n",
    "        df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n",
    "        df[coluna] = df[coluna].fillna((df[coluna].shift() + df[coluna].shift(-1)) / 2)\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 7: Substituir NaNs por zero se o valor acima ou abaixo do NaN for zero ###\n",
    "def substituir_nans_por_zero(df, colunas_para_preencher):\n",
    "    \"\"\"Substitui NaNs por 0 se o valor acima ou abaixo do NaN for 0.\"\"\"\n",
    "    for coluna in colunas_para_preencher:\n",
    "        df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n",
    "        indices_nan = df[coluna][df[coluna].isna()].index\n",
    "        for indice_nan in indices_nan:\n",
    "            if indice_nan > 0:\n",
    "                ultimo_valor_anterior = df[coluna][indice_nan - 1]\n",
    "                if pd.notna(ultimo_valor_anterior) and ultimo_valor_anterior == 0:\n",
    "                    df.at[indice_nan, coluna] = 0\n",
    "                    continue  # Passar para o próximo NaN se o valor anterior for zero\n",
    "            if indice_nan < len(df[coluna]) - 1:\n",
    "                proximo_valor_posterior = df[coluna][indice_nan + 1]\n",
    "                if pd.notna(proximo_valor_posterior) and proximo_valor_posterior == 0:\n",
    "                    df.at[indice_nan, coluna] = 0\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 8: Substituir NaNs pelo valor anterior se o valor acima ou abaixo do NaN for igual ###\n",
    "def substituir_nans_com_valor_anterior_igual(df, colunas_para_preencher):\n",
    "    \"\"\"Substitui NaNs pelo valor anterior se o valor acima ou abaixo do NaN for igual.\"\"\"\n",
    "    for coluna in colunas_para_preencher:\n",
    "        indices_nan = df[coluna][df[coluna].isna()].index\n",
    "        for indice_nan in indices_nan:\n",
    "            if indice_nan > 0:\n",
    "                primeiro_valor_anterior = df[coluna][indice_nan - 1]\n",
    "                if indice_nan < len(df[coluna]) - 1:\n",
    "                    proximo_valor_posterior = df[coluna][indice_nan + 1]\n",
    "                    if primeiro_valor_anterior == proximo_valor_posterior:\n",
    "                        df.at[indice_nan, coluna] = primeiro_valor_anterior\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 9: Interpolar os NaNs em cada coluna com base nos valores imediatamente acima e abaixo ###\n",
    "def interpolar_nans(df, colunas_para_preencher):\n",
    "    \"\"\"Interpola os NaNs em cada coluna com base nos valores imediatamente acima e abaixo.\"\"\"\n",
    "    for coluna in colunas_para_preencher:\n",
    "        df[coluna] = df[coluna].interpolate(method='linear')\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 10: Remover duplicados\n",
    "def remover_duplicatas(df, colunas_chave):\n",
    "    \"\"\"Remove linhas duplicadas com base em colunas específicas.\"\"\"\n",
    "    df.drop_duplicates(subset=colunas_chave, inplace=True)\n",
    "    return df\n",
    "\n",
    "### FUNÇÃO 11: Salvar o DataFrame como um arquivo pickle e, opcionalmente, um arquivo CSV ###\n",
    "def salvar_arquivos(df, caminho_arquivo_pkl, pasta_saida, save_csv=False):\n",
    "    \"\"\"Salva o DataFrame como um arquivo pickle e, opcionalmente, um arquivo CSV.\"\"\"\n",
    "    caminho_arquivo_pkl_atualizado = os.path.join(pasta_saida, os.path.basename(caminho_arquivo_pkl).replace('.pkl', '_sem_missing_values.pkl'))\n",
    "\n",
    "    # Salvar o arquivo pickle\n",
    "    df.to_pickle(caminho_arquivo_pkl_atualizado)\n",
    "\n",
    "    # Salvar o arquivo CSV, se a opção save_csv for True\n",
    "    if save_csv:\n",
    "        caminho_arquivo_csv = os.path.join(pasta_saida, os.path.basename(caminho_arquivo_pkl).replace('.pkl', '_sem_missing_values.csv'))\n",
    "        df.to_csv(caminho_arquivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEITURA DAS FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre cada caminho de arquivo\n",
    "for caminho_arquivo_pkl in caminho_arquivos_pkl:\n",
    "    # Ler os dados do arquivo .pkl\n",
    "    df = ler_dados_pickle(caminho_arquivo_pkl)\n",
    "    \n",
    "    ### CHAMADA 2: Deletar colunas específicas do DataFrame ###\n",
    "    df = deletar_colunas(df)\n",
    "\n",
    "    ### CHAMADA 3: Substituir valores comentados por NaN ###\n",
    "    df = substituir_valores_comentados_por_nan(df)\n",
    "\n",
    "    ### CHAMADA 4: Substituir virgulas por pontos\n",
    "    df = substituir_virgulas_por_pontos(df)\n",
    "\n",
    "    ### CHAMADA 5: Converter strings NaN para NaN numérico ###\n",
    "    df = converter_str_nan_para_numerico(df)\n",
    "\n",
    "    ### CHAMADA 6: Preencher os NaN em todas as colunas do DataFrame, exceto as especificadas ###\n",
    "    colunas_para_preencher = [coluna for coluna in df.columns if coluna not in ['index', 'Data', 'Hora']]\n",
    "    df = preencher_nans_com_media(df, colunas_para_preencher)\n",
    "\n",
    "    ### CHAMADA 7: Substituir NaNs por zero se o valor acima ou abaixo do NaN for zero ###\n",
    "    df = substituir_nans_por_zero(df, colunas_para_preencher)\n",
    "\n",
    "    ### CHAMADA 8: Substituir NaNs pelo valor anterior se o valor acima ou abaixo do NaN for igual ###\n",
    "    df = substituir_nans_com_valor_anterior_igual(df, colunas_para_preencher)\n",
    "\n",
    "    ### CHAMADA 9: Interpolar os NaNs com base nos valores imediatamente acima e abaixo ###\n",
    "    df = interpolar_nans(df, colunas_para_preencher)\n",
    "\n",
    "    ### CHAMADA 10: remover linhas duplicadas\n",
    "    colunas_chave = ['Data', 'Hora']  # Colunas chave para identificar duplicatas\n",
    "    df = remover_duplicatas(df, colunas_chave)\n",
    "\n",
    "    # CHAMADA 11: Chamar a função para salvar os arquivos na pasta de saída desejada\n",
    "    salvar_arquivos(df, caminho_arquivo_pkl, pasta_saida_desejada, save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
